{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plinder-org/moving_beyond_memorisation/blob/main/notebooks/pinder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtxuR43f72e0"
      },
      "source": [
        "# Pinder"
      ],
      "id": "DtxuR43f72e0"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/conda-incubator/condacolab.git@0.1.x\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "metadata": {
        "id": "3O0jX8KqLNJW",
        "outputId": "2ea31211-9819-4210-c746-9c5a66239929",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "3O0jX8KqLNJW",
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "‚ú®üç∞‚ú® Everything looks OK!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pinder"
      ],
      "metadata": {
        "id": "hKL7Q3UJLP_w"
      },
      "id": "hKL7Q3UJLP_w",
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-cluster py3Dmol"
      ],
      "metadata": {
        "id": "yuc4cFrLnBc0",
        "outputId": "3262164a-3a74-4d1f-ee59-e56e17c4d747",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "yuc4cFrLnBc0",
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.10/site-packages (1.6.3)\n",
            "Requirement already satisfied: py3Dmol in /usr/local/lib/python3.10/site-packages (2.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/site-packages (from torch-cluster) (1.14.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.23.5 in /usr/local/lib/python3.10/site-packages (from scipy->torch-cluster) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0000bed-ebd4-4f95-8d63-c87cba8565ac"
      },
      "source": [
        "# Pinder index"
      ],
      "id": "b0000bed-ebd4-4f95-8d63-c87cba8565ac"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c23b631-1861-426b-9510-2888cf3aee5b"
      },
      "source": [
        "## Download the dataset\n",
        "\n",
        "NOTE: the default location for the dataset is `~/.local/share/pinder/<release version>`\n",
        "\n",
        "If you want to use a different location, you can do so by setting the `PINDER_BASE_DIR` environment variable.\n",
        "\n",
        "The base dir refers to a fully qualified path name up until the `<release version>` (not inclusive).\n",
        "\n",
        "For instance, you could:\n",
        "```\n",
        "export PINDER_BASE_DIR=~/my-custom-location-for-pinder/pinder\n",
        "```\n",
        "\n",
        "You can always check the current location of the dataset like so:\n",
        "```python\n",
        "from pinder.core import get_pinder_location\n",
        "get_pinder_location()\n",
        "```"
      ],
      "id": "2c23b631-1861-426b-9510-2888cf3aee5b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecb996d2-2676-4eee-8636-01e26227bdeb"
      },
      "outputs": [],
      "source": [
        "from pinder.core import get_pinder_location\n",
        "get_pinder_location()\n"
      ],
      "id": "ecb996d2-2676-4eee-8636-01e26227bdeb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1da603c9-4896-4f4c-be22-b1d79af23808"
      },
      "source": [
        "### To download the complete dataset run the following\n",
        "Note: Pinder dataset contains millions of structures and takes time to download. Due to this we will explore the capabilities of Pinder by loading the dataset incrementally, using its lazy loading capabilities.\n"
      ],
      "id": "1da603c9-4896-4f4c-be22-b1d79af23808"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "301ca179-0394-4106-be38-7ddab0caa16d"
      },
      "outputs": [],
      "source": [
        "from pinder.core import download_dataset\n",
        "# download_dataset()\n"
      ],
      "id": "301ca179-0394-4106-be38-7ddab0caa16d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ada695c7-923c-4f58-9e8f-2edd715a31e6"
      },
      "source": [
        "### Alternatively, use the CLI script `pinder_download`\n",
        "\n",
        "```bash\n",
        "pinder_download --help\n",
        "\n",
        "usage: Download latest pinder dataset to disk [-h] [--pinder_base_dir PINDER_BASE_DIR] [--pinder_release PINDER_RELEASE] [--skip_inflation]\n",
        "\n",
        "optional arguments:\n",
        "  -h, --help            show this help message and exit\n",
        "  --pinder_base_dir PINDER_BASE_DIR\n",
        "                        specify a non-default pinder base directory\n",
        "  --pinder_release PINDER_RELEASE\n",
        "                        specify a pinder dataset version\n",
        "  --skip_inflation      if passed, will only download the compressed archives without unpacking\n",
        "```"
      ],
      "id": "ada695c7-923c-4f58-9e8f-2edd715a31e6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31599fbd-5d69-4710-bf42-960ecf2fdc5d"
      },
      "source": [
        "### The full dataset should look like this\n",
        "\n",
        "```bash\n",
        "~/.local/share/pinder/<release version>/\n",
        "    pdbs/\n",
        "    test_set_pdbs/\n",
        "    mappings/\n",
        "    index.parquet\n",
        "    metadata.parquet\n",
        "```"
      ],
      "id": "31599fbd-5d69-4710-bf42-960ecf2fdc5d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pinder Annotations\n",
        "\n",
        "### RCSB Annotations\n",
        "\n",
        "Annotations were obtained from the RCSB NextGen database. The following annotations are included:\n",
        "\n",
        "1. Oligomeric state of the protein complex (homodimer, heterodimer, oligomer or higher-order complexes)\n",
        "\n",
        "2. Structure determination method (X-Ray, CryoEM, NMR)\n",
        "\n",
        "3. Resolution\n",
        "\n",
        "4. Interfacial gaps, defined as structurally-unresolved segments on PPI interfaces\n",
        "\n",
        "5. Number of distinct atom types. Many earlier Cryo-EM structures contain only a few atom-types such as only CŒ± or backbone atoms\n",
        "\n",
        "6. Whether the interface is likely to be a physiological or crystal contact, annotated using Prodigy\n",
        "\n",
        "7. Structural elongation, defined as the maximum variance of coordinates projected onto the largest principal component. This allows detection of long end-to-end stacked complexes, likely to be repetitive with small interfaces\n",
        "\n",
        "8. Planarity, defined as deviation of interfacial CŒ± atoms from the fitted plane. This interface characteristic quantifies interfacial shape complementarity. Transient complexes have smaller and more planar interfaces than permanent and structural scaffold complexes\n",
        "\n",
        "9. Number of components, defined as the number of connected components of a 10√Ö CŒ± radius graph. This allows detection of structurally discontinuous domains\n",
        "\n",
        "10. Intermolecular contacts (labeled as polar or apolar)\n",
        "\n",
        "### Pinder Annotations\n",
        "\n",
        "A core philosophy behind pinder is to provide a large, unfiltered training dataset to derive data mixes for evaluating the impact of different data selection strategies. To that end, we provide extensive tooling for leveraging annotations in filters.\n",
        "\n",
        "A large set of quality control annotations including interface cluster, resolution, interfacial gaps, planarity, elongation, and more can be accessed via the PinderSystem object or directly in data frames. We also provide the effective MSA Depth (number of effective sequences: $N_{eff}$\n",
        ") calculated for each of the test members in `PINDER-XL/S/AF2` to allow accurate performance assessment by evolutionary information.\n",
        "\n",
        "All systems are indexed and their annotations are stored in two main `parquet` files: `index.parquet` and `metadata.parquet`. Upon loading a pinder system, this data is embedded into individual `PinderSystem` objects. Each `PinderSystem` object features an `.entry` property, exposing primary annotations from the index, and a `.metadata` property, providing detailed metadata. For detailed schemas of these properties, we will explore the index and metadata files, and later with the `IndexEntry` and `MetadataEntry` objects. Their fields are shown below for reference:\n",
        "\n",
        "</br></br>\n",
        "\n",
        "Table 1: Pinder Index entry fields\n",
        "\n",
        "| Field | Type | Description |\n",
        "|-------|------|-------------|\n",
        "| split | string | The type of data split (e.g., 'train', 'test'). |\n",
        "| id | string | The unique identifier for the dataset entry. |\n",
        "| pdb_id | string | The PDB identifier associated with the entry. |\n",
        "| cluster_id | string | The cluster identifier associated with the entry. |\n",
        "| cluster_id_R | string | The cluster identifier associated with receptor dimer body. |\n",
        "| cluster_id_L | string | The cluster identifier associated with ligand dimer body. |\n",
        "| pinder_s | boolean | Flag indicating if the entry is part of the Pinder-S dataset. |\n",
        "| pinder_xl | boolean | Flag indicating if the entry is part of the Pinder-XL dataset. |\n",
        "| pinder_af2 | boolean | Flag indicating if the entry is part of the Pinder-AF2 dataset. |\n",
        "| uniprot_R | string | The UniProt identifier for the receptor protein. |\n",
        "| uniprot_L | string | The UniProt identifier for the ligand protein. |\n",
        "| holo_R_pdb | string | The PDB identifier for the holo form of the receptor protein. |\n",
        "| holo_L_pdb | string | The PDB identifier for the holo form of the ligand protein. |\n",
        "| predicted_R_pdb | string | The PDB identifier for the predicted structure of the receptor protein. |\n",
        "| predicted_L_pdb | string | The PDB identifier for the predicted structure of the ligand protein. |\n",
        "| apo_R_pdb | string | The PDB identifier for the apo form of the receptor protein. |\n",
        "| apo_L_pdb | string | The PDB identifier for the apo form of the ligand protein. |\n",
        "| apo_R_pdbs | string | The PDB identifiers for the apo forms of the receptor protein. |\n",
        "| apo_L_pdbs | string | The PDB identifiers for the apo forms of the ligand protein. |\n",
        "| holo_R | boolean | Flag indicating if the holo form of the receptor protein is available. |\n",
        "| holo_L | boolean | Flag indicating if the holo form of the ligand protein is available. |\n",
        "| predicted_R | boolean | Flag indicating if the predicted structure of the receptor protein is available. |\n",
        "| predicted_L | boolean | Flag indicating if the predicted structure of the ligand protein is available. |\n",
        "| apo_R | boolean | Flag indicating if the apo form of the receptor protein is available. |\n",
        "| apo_L | boolean | Flag indicating if the apo form of the ligand protein is available. |\n",
        "| apo_R_quality | string | Classification of apo receptor pairing quality. |\n",
        "| apo_L_quality | string | Classification of apo ligand pairing quality. |\n",
        "| chain1_neff | number | The Neff value for the first chain in the protein complex. |\n",
        "| chain2_neff | number | The Neff value for the second chain in the protein complex. |\n",
        "| chain_R | string | The chain identifier for the receptor protein. |\n",
        "| chain_L | string | The chain identifier for the ligand protein. |\n",
        "| contains_antibody | boolean | Flag indicating if the protein complex contains an antibody as per SAbDab. |\n",
        "| contains_antigen | boolean | Flag indicating if the protein complex contains an antigen as per SAbDab. |\n",
        "| contains_enzyme | boolean | Flag indicating if the protein complex contains an enzyme as per EC ID number. |\n",
        "\n",
        "</br></br>\n",
        "\n",
        "Table 2: Metadata Entry Fields\n",
        "\n",
        "| Field | Type | Description |\n",
        "|-------|------|-------------|\n",
        "| id | string | The unique identifier for the PINDER entry. |\n",
        "| entry_id | string | The RCSB entry identifier associated with the PINDER entry. |\n",
        "| method | string | The experimental method for structure determination. |\n",
        "| date | string | Date of deposition into RCSB PDB. |\n",
        "| release_date | string | Date of initial public release in RCSB PDB. |\n",
        "| resolution | number | The resolution of the experimental structure. |\n",
        "| label | string | Classification of the interface. |\n",
        "| probability | number | Probability that the protein complex is a true biological complex. |\n",
        "| chain1_id | string | The Receptor chain identifier associated with the dimer entry. |\n",
        "| chain2_id | string | The Ligand chain identifier associated with the dimer entry. |\n",
        "| assembly | integer | Which bioassembly is used to derive the structure. |\n",
        "| assembly_details | string | How the bioassembly information was derived. |\n",
        "| oligomeric_details | string | Description of the oligomeric state of the protein complex. |\n",
        "| oligomeric_count | integer | The oligomeric count associated with the dataset entry. |\n",
        "| biol_details | string | The biological assembly details associated with the dataset entry. |\n",
        "| complex_type | string | The type of the complex in the dataset entry. |\n",
        "| chain_1 | string | New chain id generated post-bioassembly generation (receptor chain). |\n",
        "| asym_id_1 | string | The first asymmetric identifier (author chain ID) |\n",
        "| chain_2 | string | New chain id generated post-bioassembly generation (ligand chain). |\n",
        "| asym_id_2 | string | The second asymmetric identifier (author chain ID) |\n",
        "| length1 | integer | The number of amino acids in the first (receptor) chain. |\n",
        "| length2 | integer | The number of amino acids in the second (ligand) chain. |\n",
        "| length_resolved_1 | integer | The structurally resolved (CA) length of the first (receptor) chain. |\n",
        "| length_resolved_2 | integer | The structurally resolved (CA) length of the second (ligand) chain. |\n",
        "| number_of_components_1 | integer | The number of connected components in the first (receptor) chain. |\n",
        "| number_of_components_2 | integer | The number of connected components in the second (receptor) chain. |\n",
        "| link_density | number | Density of contacts at the interface as reported by PRODIGY-cryst. |\n",
        "| planarity | number | Deviation of interfacial CŒ± atoms from the fitted plane. |\n",
        "| max_var_1 | number | The maximum variance of coordinates projected onto the largest principal component. |\n",
        "| max_var_2 | number | The maximum variance of coordinates projected onto the largest principal component. |\n",
        "| num_atom_types | integer | Number of unique atom types in structure. |\n",
        "| n_residue_pairs | integer | The number of residue pairs at the interface. |\n",
        "| n_residues | integer | The number of residues at the interface. |\n",
        "| buried_sasa | number | The buried solvent accessible surface area upon complex formation. |\n",
        "| intermolecular_contacts | integer | The total number of intermolecular contacts at the interface. |\n",
        "| charged_charged_contacts | integer | Intermolecular contacts between charged amino acids. |\n",
        "| charged_polar_contacts | integer | Intermolecular contacts between charged and polar amino acids. |\n",
        "| charged_apolar_contacts | integer | Intermolecular contacts between charged and apolar amino acids. |\n",
        "| polar_polar_contacts | integer | Intermolecular contacts between polar amino acids. |\n",
        "| apolar_polar_contacts | integer | Intermolecular contacts between apolar and polar amino acids. |\n",
        "| apolar_apolar_contacts | integer | Intermolecular contacts between apolar amino acids. |\n",
        "| interface_atom_gaps_4A | integer | Number of interface atoms within a 4√Ö radius of a residue gap. |\n",
        "| missing_interface_residues_4A | integer | Number of interface residues within a 4√Ö radius of a residue gap. |\n",
        "| interface_atom_gaps_8A | integer | Number of interface atoms within an 8√Ö radius of a residue gap. |\n",
        "| missing_interface_residues_8A | integer | Number of interface residues within an 8√Ö radius of a residue gap. |\n",
        "| entity_id_R | integer | The RCSB PDB entity_id corresponding to the receptor dimer chain. |\n",
        "| entity_id_L | integer | The RCSB PDB entity_id corresponding to the ligand dimer chain. |\n",
        "| pdb_strand_id_R | string | The RCSB PDB pdb_strand_id (author chain) corresponding to the receptor dimer chain. |\n",
        "| pdb_strand_id_L | string | The RCSB PDB pdb_strand_id (author chain) corresponding to the ligand dimer chain. |\n",
        "| ECOD_names_R | string | The RCSB-derived ECOD domain protein family name(s) for the receptor dimer chain. |\n",
        "| ECOD_names_L | string | The RCSB-derived ECOD domain protein family name(s) for the ligand dimer chain. |\n"
      ],
      "metadata": {
        "id": "2lDTZ9wGFGfJ"
      },
      "id": "2lDTZ9wGFGfJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b629c20c-5a9f-427c-81ae-e7444b873372"
      },
      "source": [
        "## Pinder metadata API"
      ],
      "id": "b629c20c-5a9f-427c-81ae-e7444b873372"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6B6gViVPSUoi"
      },
      "outputs": [],
      "source": [
        "from pinder.core import get_index\n",
        "\n",
        "index = get_index()\n",
        "index"
      ],
      "id": "6B6gViVPSUoi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c5ad9f9-c15b-40c7-bc1b-7a4d24bd9d4e"
      },
      "outputs": [],
      "source": [
        "from pinder.core import get_metadata\n",
        "\n",
        "metadata = get_metadata()\n",
        "metadata\n"
      ],
      "id": "7c5ad9f9-c15b-40c7-bc1b-7a4d24bd9d4e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Break - Q&A"
      ],
      "metadata": {
        "id": "u5qgab8_zYN2"
      },
      "id": "u5qgab8_zYN2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pinder System"
      ],
      "metadata": {
        "id": "LaXBzpVb87iq"
      },
      "id": "LaXBzpVb87iq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "656e3d46-72b2-42fd-b61c-f13d1a113bce"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from pinder.core import PinderSystem\n"
      ],
      "id": "656e3d46-72b2-42fd-b61c-f13d1a113bce"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00427ee6-105a-4901-b647-52d667cf9eac"
      },
      "source": [
        "Example usage of Pinder index API shown below. For more detailed usage examples, check the [pinder-index](https://pinder-org.github.io/pinder/pinder-index.html) tutorial.  "
      ],
      "id": "00427ee6-105a-4901-b647-52d667cf9eac"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71223020-07c6-4a55-ba37-2343e7b4c400"
      },
      "outputs": [],
      "source": [
        "index = get_index()\n",
        "hetero_test_apo = index.query(\n",
        "    '(uniprot_L != uniprot_R) and split == \"test\" and (apo_R and apo_L)'\n",
        ")\n",
        "hetero_test_apo.reset_index(drop=True, inplace=True)\n",
        "hetero_test_apo\n"
      ],
      "id": "71223020-07c6-4a55-ba37-2343e7b4c400"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa97b738-8a64-4e43-b1dc-17b226c470fb"
      },
      "outputs": [],
      "source": [
        "pinder_id = list(hetero_test_apo.id)[2]\n",
        "pinder_id\n"
      ],
      "id": "aa97b738-8a64-4e43-b1dc-17b226c470fb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b68d224-b8f2-4037-ad74-439f5345e64e"
      },
      "source": [
        "## PinderSystem API - base class representing `Structure`'s in a pinder entry"
      ],
      "id": "1b68d224-b8f2-4037-ad74-439f5345e64e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf0386fa-aa33-49b5-b0a8-02c5c2b24e37"
      },
      "outputs": [],
      "source": [
        "# Simplest interface - get a single pinder system\n",
        "ps = PinderSystem(pinder_id)\n",
        "ps\n"
      ],
      "id": "cf0386fa-aa33-49b5-b0a8-02c5c2b24e37"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8d0ce8c7-8679-49cb-a47b-0c07a787d9b7"
      },
      "outputs": [],
      "source": [
        "holo_L, holo_R = ps.holo_ligand, ps.holo_receptor\n",
        "pred_L, pred_R = ps.pred_ligand, ps.pred_receptor\n",
        "apo_L, apo_R = ps.apo_ligand, ps.apo_receptor\n",
        "\n",
        "holo_L\n"
      ],
      "id": "8d0ce8c7-8679-49cb-a47b-0c07a787d9b7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice the printed `PinderSystem` object has the following properties:\n",
        "* `native` - the ground-truth dimer complex\n",
        "* `holo_receptor` - the receptor chain (monomer) from the ground-truth complex\n",
        "* `holo_ligand` - the ligand chain (monomer) from the ground-truth complex\n",
        "* `apo_receptor` - the canonical _apo_ chain (monomer) paired to the receptor chain\n",
        "* `apo_ligand` - the canonical _apo_ chain (monomer) paired to the ligand chain\n",
        "* `pred_receptor` - the AlphaFold2 predicted monomer paired to the receptor chain  \n",
        "* `pred_ligand` - the AlphaFold2 predicted monomer paired to the ligand chain\n",
        "\n",
        "\n",
        "These properties are pointers to `Structure` objects. The `Structure` object provides the most direct mode of access to structures and associated properties.\n",
        "\n",
        "**Note: not all systems have an apo and/or predicted structure for all chains of the ground-truth dimer complex!**\n",
        "\n",
        "As was the case in the example above, when the alternative monomers are not available, the property will have a value of `None`.\n",
        "\n",
        "You can determine which systems have which alternative monomer pairings _a priori_ by looking at the boolean columns in the index `apo_R` and `apo_L` for the apo receptor and ligand, and `predicted_R` and `predicted_L` for the predicted receptor and ligand, respectively.\n",
        "\n",
        "\n",
        "For instance, we can load a different system that _does_ have apo receptor and ligand as such:"
      ],
      "metadata": {
        "id": "_4AmT3eJ8rFi"
      },
      "id": "_4AmT3eJ8rFi"
    },
    {
      "cell_type": "code",
      "source": [
        "apo_system = PinderSystem(index.query('apo_R and apo_L').id.iloc[0])"
      ],
      "metadata": {
        "id": "lNqbwsr99B1G"
      },
      "id": "lNqbwsr99B1G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize some of the complexes\n",
        "from pathlib import Path\n",
        "import py3Dmol\n",
        "\n",
        "ground_truth = apo_system.native.filepath\n",
        "apo_complex = apo_system.create_apo_complex()\n",
        "apo_complex.to_pdb()\n",
        "\n",
        "# Extract interface residues in the apo-superimposed complex for visualization\n",
        "apo_contacts = apo_complex.get_contacts()\n",
        "apo_interface_res = apo_complex.get_interface_residues(apo_contacts)\n",
        "\n",
        "# Viewer documentation: https://3dmol.org/doc/GLViewer.html\n",
        "view = py3Dmol.view(width=900, height=900)\n",
        "view.removeAllModels()\n",
        "view.setViewStyle({'style':'outline','color':'black','width':0.1})\n",
        "view.setBackgroundColor('black')\n",
        "# Show the reference (holo) structure\n",
        "view.addModel(open(ground_truth, 'r').read(),'pdb',\n",
        "             {\"style\": {'cartoon': {'color':'hotpink'}}})\n",
        "view.setStyle({'chain':'R'},{'cartoon': {'color':'dodgerblue', 'arrows':True, 'tubes': False, 'ribbon': False, 'style': 'edged'}})\n",
        "view.setStyle({'chain':'L'},{'cartoon': {'color':'hotpink', 'arrows':True, 'tubes':False, 'ribbon': False, 'style':'edged'}})\n",
        "view.addSurface(py3Dmol.VDW,{'opacity':0.6,'color':'white'})\n",
        "\n",
        "# Show the monomer-superposed apo complex\n",
        "view.addModel(\n",
        "    open(apo_complex.filepath, 'r').read(),\n",
        "    'pdb',\n",
        "    {\"style\": {'cartoon': {'color':'lightskyblue'}}}\n",
        ")\n",
        "# Color the apo ligand chain in light pink\n",
        "view.setStyle({'chain':'L', \"model\": 1},{'cartoon': {'color':'lightpink', 'arrows':True, 'tubes': False, 'ribbon': False, 'style': 'edged'}})\n",
        "# Show the interface residues as stick representation\n",
        "view.setStyle({\"chain\": \"R\", \"resi\": list(map(str, sorted(apo_interface_res[\"R\"])))}, {\"stick\": {\"colorscheme\": \"cyanCarbon\", \"radius\": 0.15}})\n",
        "view.setStyle({\"chain\": \"L\", \"resi\": list(map(str, sorted(apo_interface_res[\"L\"])))}, {\"stick\": {\"colorscheme\": \"pinkCarbon\", \"radius\": 0.15}})\n",
        "view.zoomTo()\n",
        "view.spin(\"y\")\n",
        "view.show()"
      ],
      "metadata": {
        "id": "yt_ZblLwz8mt"
      },
      "id": "yt_ZblLwz8mt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcb458c6-2411-4530-8d1b-49432f6a9710"
      },
      "source": [
        "## Classify system difficulty based on degree of conformational shift in unbound and bound"
      ],
      "id": "dcb458c6-2411-4530-8d1b-49432f6a9710"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23e418c0-e9a9-4e6f-a368-f28fe552ca3e"
      },
      "outputs": [],
      "source": [
        "ps.unbound_difficulty(\"apo\")"
      ],
      "id": "23e418c0-e9a9-4e6f-a368-f28fe552ca3e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66e74ce5-7bd1-4d3c-9949-ac684f58709f"
      },
      "outputs": [],
      "source": [
        "ps.unbound_difficulty(\"predicted\")"
      ],
      "id": "66e74ce5-7bd1-4d3c-9949-ac684f58709f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10dd61ad-941b-4299-b264-32cd626a9c36"
      },
      "source": [
        "## Illustrating utilities available in `Structure` instances"
      ],
      "id": "10dd61ad-941b-4299-b264-32cd626a9c36"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "229cc534-be79-4a94-9019-ab441f402eb0"
      },
      "outputs": [],
      "source": [
        "holo_L.filter(\"atom_name\", mask=[\"CA\"])\n"
      ],
      "id": "229cc534-be79-4a94-9019-ab441f402eb0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89a84179-26bb-4a10-86df-febe88266968"
      },
      "outputs": [],
      "source": [
        "apo_L.filter(\"atom_name\", mask=[\"CA\"])\n"
      ],
      "id": "89a84179-26bb-4a10-86df-febe88266968"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dc21c5c-acf5-4049-adc4-143515d7f04a"
      },
      "source": [
        "## Can also filter \"in place\" rather than returning a copy (a la pandas)"
      ],
      "id": "2dc21c5c-acf5-4049-adc4-143515d7f04a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "268518de-a794-4290-8398-4ec4e2cc402b"
      },
      "outputs": [],
      "source": [
        "apo_L.filter(\"atom_name\", mask=[\"CA\"], copy=False)"
      ],
      "id": "268518de-a794-4290-8398-4ec4e2cc402b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcac0379-5c72-4312-9592-2deff39f5bfa"
      },
      "outputs": [],
      "source": [
        "(\n",
        "    ps.apo_ligand.filter(\"atom_name\", mask=[\"CA\"]),\n",
        "    ps.holo_ligand.filter(\"atom_name\", mask=[\"CA\"])\n",
        ")\n"
      ],
      "id": "dcac0379-5c72-4312-9592-2deff39f5bfa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0c49149-8a88-44d8-9d67-f88a85e6e808"
      },
      "source": [
        "## Create masked unbound complex aligned to bound for apo"
      ],
      "id": "d0c49149-8a88-44d8-9d67-f88a85e6e808"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdda523e-0a75-4e56-9b01-9923a361a876"
      },
      "outputs": [],
      "source": [
        "apo_complex = ps.create_apo_complex()\n",
        "apo_complex\n"
      ],
      "id": "fdda523e-0a75-4e56-9b01-9923a361a876"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "149e2564-41a5-4150-b427-56be5a063d11"
      },
      "outputs": [],
      "source": [
        "# dataframe representation of the Structure atom_array\n",
        "apo_complex.dataframe"
      ],
      "id": "149e2564-41a5-4150-b427-56be5a063d11"
    },
    {
      "cell_type": "markdown",
      "id": "0aac6d07-925c-4a65-88bd-528a19b9853a",
      "metadata": {
        "id": "0aac6d07-925c-4a65-88bd-528a19b9853a"
      },
      "source": [
        "# Accessing and loading data for training\n",
        "\n",
        "In order to access the train and val splits for PINDER, please refer to the [pinder documentation](https://github.com/pinder-org/pinder/tree/main?tab=readme-ov-file#%EF%B8%8F-getting-the-dataset)\n",
        "\n",
        "Once you have downloaded the pinder dataset, either via the `pinder` package or directly through `gsutil`, you will have all of the necessary files for training.\n",
        "\n",
        "To get a list of those systems and their split labels, refer to the `pinder` index.\n",
        "\n",
        "**We will start by looking at the most basic way to load items from the training and validation set: via `PinderSystem` objects**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6cfd590-b725-4fca-8793-ae7b0a52f312",
      "metadata": {
        "id": "f6cfd590-b725-4fca-8793-ae7b0a52f312"
      },
      "outputs": [],
      "source": [
        "index = get_index()\n",
        "\n",
        "n_samples = 50\n",
        "\n",
        "system_ids = index.query(\n",
        "    f'(apo_R & apo_L) and (split == \"train\")'\n",
        ").sample(n_samples).id.tolist()\n",
        "\n",
        "loader = (PinderSystem(id) for id in system_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "146046b4-cf0e-4a00-9540-6155f0085c5c",
      "metadata": {
        "id": "146046b4-cf0e-4a00-9540-6155f0085c5c"
      },
      "source": [
        "### Using the PinderLoader to load, filter and transform systems\n",
        "\n",
        "While the `PinderSystem` object provides a self-contained access to structures associated with a dimer system, the `PinderLoader` provides a base abstraction for how to iterate over systems, apply optional filters and/or transforms, and return the systems as an iterator. This construct is covered in a [different tutorial](https://pinder-org.github.io/pinder/pinder-loader.html).\n",
        "\n",
        "Using the `PinderLoader` is **not** necessary to load systems in your own framework. It is simply one of the provided mechanisms if you find it useful.\n",
        "\n",
        "Pinder loader brings together filters, transforms and writers to create a generic `PinderSystem` iterator. It takes either a split name or a list of system IDs as input and can be used to sample alternative monomers to form dimer complexes to serve as e.g. features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95707004-e026-40c4-abc1-a8fa84614b6f",
      "metadata": {
        "id": "95707004-e026-40c4-abc1-a8fa84614b6f"
      },
      "source": [
        "### Loading a specific split\n",
        "Note: only the test dataset has a subset defined (`pinder_s, pinder_xl, pinder_af2`)\n",
        "\n",
        "For train and val, you could just do:\n",
        "```python\n",
        "train_loader = PinderLoader(split=\"train\")\n",
        "val_loader = PinderLoader(split=\"val\")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e09ccc9-215f-4d8e-a08f-1de96bb42131",
      "metadata": {
        "id": "6e09ccc9-215f-4d8e-a08f-1de96bb42131"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from pinder.core import PinderLoader\n",
        "from pinder.core.loader import filters\n",
        "\n",
        "base_filters = [\n",
        "    filters.FilterByMissingHolo(),\n",
        "    filters.FilterSubByContacts(min_contacts=5, radius=10.0, calpha_only=True),\n",
        "    filters.FilterDetachedHolo(radius=12, max_components=2),\n",
        "]\n",
        "sub_filters = [\n",
        "    filters.FilterSubByAtomTypes(min_atom_types=4),\n",
        "    filters.FilterByHoloOverlap(min_overlap=5),\n",
        "    filters.FilterByHoloSeqIdentity(min_sequence_identity=0.8),\n",
        "    filters.FilterSubRmsds(rmsd_cutoff=7.5),\n",
        "    filters.FilterDetachedSub(radius=12, max_components=2),\n",
        "]\n",
        "\n",
        "loader = PinderLoader(\n",
        "    split=\"test\",\n",
        "    subset=\"pinder_af2\",\n",
        "    monomer_priority=\"holo\",\n",
        "    base_filters = base_filters,\n",
        "    sub_filters = sub_filters\n",
        ")\n",
        "\n",
        "loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7bcbe6e-4bd3-435c-9ff0-cf611f6bf9cf",
      "metadata": {
        "id": "f7bcbe6e-4bd3-435c-9ff0-cf611f6bf9cf"
      },
      "outputs": [],
      "source": [
        "len(loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fecd34da-c91d-400c-bbda-64d6cccb8e0b",
      "metadata": {
        "id": "fecd34da-c91d-400c-bbda-64d6cccb8e0b"
      },
      "outputs": [],
      "source": [
        "data = loader[0]\n",
        "print(f\"Data is a {type(data)}\")\n",
        "system, feature_complex, target_complex = data\n",
        "type(system), type(feature_complex), type(target_complex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdb3327d-26d2-46fc-95ea-de2ea2fc0516",
      "metadata": {
        "id": "bdb3327d-26d2-46fc-95ea-de2ea2fc0516"
      },
      "outputs": [],
      "source": [
        "# # You can also use it as an iterator\n",
        "from tqdm import tqdm\n",
        "max_samples = 10\n",
        "loaded_ids = []\n",
        "for (system, feature_complex, target_complex) in tqdm(loader):\n",
        "    if len(loaded_ids) >= max_samples:\n",
        "        break\n",
        "    loaded_ids.append(system.entry.id)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a1cb330-7034-4522-9763-093993a1bb4e",
      "metadata": {
        "id": "9a1cb330-7034-4522-9763-093993a1bb4e"
      },
      "source": [
        "### Loading a specific list of systems\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77d0f734-508a-4b1e-a4f3-acb8590869a0",
      "metadata": {
        "id": "77d0f734-508a-4b1e-a4f3-acb8590869a0"
      },
      "outputs": [],
      "source": [
        "systems = [\n",
        "    \"1df0__A1_Q07009--1df0__B1_Q64537\",\n",
        "    \"117e__A1_P00817--117e__B1_P00817\",\n",
        "]\n",
        "loader = PinderLoader(\n",
        "    ids=systems,\n",
        "    monomer_priority=\"holo\",\n",
        "    base_filters = base_filters,\n",
        "    sub_filters = sub_filters\n",
        ")\n",
        "passing_ids = []\n",
        "for item in loader:\n",
        "    passing_ids.append(item[0].entry.id)\n",
        "\n",
        "systems_removed_by_filters = set(systems) - set(passing_ids)\n",
        "systems_removed_by_filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3644c869-da61-4620-a054-2a3ad163f3f8",
      "metadata": {
        "id": "3644c869-da61-4620-a054-2a3ad163f3f8"
      },
      "outputs": [],
      "source": [
        "len(systems) == len(passing_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5de9d527-ffe0-4b6d-96a7-c90c137a4eb0",
      "metadata": {
        "id": "5de9d527-ffe0-4b6d-96a7-c90c137a4eb0"
      },
      "source": [
        "### Optional Pinder writer\n",
        "\n",
        "Without defining a writer for the `PinderLoader`, the loaded systems are available as a tuple of (`PinderSystem`, `Structure`, `Structure`) objects, containing the original `PinderSystem` and the sampled feature and target complexes, respectively.\n",
        "\n",
        "If you want to explicitly write the (potentially transformed) structure objects to a custom location or in a custom format (e.g. PDB, pickle, etc.), you can implement a subclass of `PinderWriterBase`.\n",
        "\n",
        "The default writer implements writing to PDB files (leveraging the `Structure.to_pdb` method on the structure objects).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b653c61-cebd-4ace-baf8-a27f1e011466",
      "metadata": {
        "id": "6b653c61-cebd-4ace-baf8-a27f1e011466"
      },
      "outputs": [],
      "source": [
        "from pinder.core.loader.writer import PinderDefaultWriter\n",
        "\n",
        "from pathlib import Path\n",
        "from tempfile import TemporaryDirectory\n",
        "\n",
        "with TemporaryDirectory() as tmp_dir:\n",
        "    temp_dir = Path(tmp_dir)\n",
        "    loader = PinderLoader(\n",
        "        ids=systems,\n",
        "        monomer_priority=\"pred\",\n",
        "        writer=PinderDefaultWriter(temp_dir)\n",
        "    )\n",
        "    assert set(loader.index.id) == set(systems)\n",
        "    for i, r in loader.index.iterrows():\n",
        "        loaded = loader[i]\n",
        "        pinder_id = r.id\n",
        "        system_dir = loader.writer.output_path / pinder_id\n",
        "        assert system_dir.is_dir()\n",
        "        print(list(system_dir.glob(\"af_*.pdb\")))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bda57a4e-2318-4876-8afb-04e287afceaa",
      "metadata": {
        "id": "bda57a4e-2318-4876-8afb-04e287afceaa"
      },
      "source": [
        "## Constructing torch datasets and dataloaders from pinder systems\n",
        "\n",
        "The remaining sections of this tutorial will be for those interested specifically in torch datasets and dataloaders.\n",
        "\n",
        "Specifically, we will show how to:\n",
        "* Implement a PyTorch `Dataset` to interface with pinder data\n",
        "* Include apo and predicted monomers in the data pipeline, with an option to target specific monomer types or randomly sample from the available types\n",
        "* Leverage `PinderSystem` and its associated methods to crop apo/predicted monomers to match the ground-truth holo monomers\n",
        "* Write filters and transforms that operate on `Structure` objects\n",
        "* Integrate annotations in data filtering and featurization\n",
        "* Create example features to use for training (you will of course choose your own features)\n",
        "* Incorporate diversity sampling in the data loader\n",
        "\n",
        "\n",
        "The `pinder.core.loader.dataset` module provides two example implementations of how to integrate the pinder dataset into a torch-based machine learning pipeline.\n",
        "\n",
        "1. `PinderDataset`: A map-style `torch.utils.data.Dataset` that can be used with torch `DataLoader`'s.\n",
        "2. `PPIDataset`: A `torch_geometric.data.Dataset` that can be used with torch-geometric `DataLoader`'s. This dataset is designed to be used with the `torch_geometric` package.\n",
        "\n",
        "Together, the two datasets provide an example implementation of how to abstract away the complexity of loading and processing multiple structures associated with each `PinderSystem` by leveraging the following utilities from pinder:\n",
        "\n",
        "* `pinder.core.PinderLoader`\n",
        "* `pinder.core.loader.filters`\n",
        "* `pinder.core.loader.transforms`\n",
        "\n",
        "The examples cover two different batch data item structures to illustrate two different use-cases:\n",
        "\n",
        "* `PinderDataset`: A batch of `(target_complex, feature_complex)` pairs, where `target_complex` and `feature_complex` are `torch.Tensor` objects representing the atomic coordinates and atom types of the holo and sampled (decoy, holo/apo/pred) complexes, respectively.\n",
        "* `PPIDataset`: A batch of `PairedPDB` objects, where the receptor and ligand are encoded separately in a heterogeneous graph, via `torch_geometric.data.HeteroData`, holding multiple node and/or edge types in disjunct storage objects.\n",
        "\n",
        "\n",
        "The remaining sections will be split into:\n",
        "1. Using the `PinderDataset` torch dataset\n",
        "2. Using the `PPIDataset` torch-geometric dataset\n",
        "3. How you could implement your own dataset & dataloader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d960b6d5-f431-4635-b6a3-8473c78f33cd",
      "metadata": {
        "id": "d960b6d5-f431-4635-b6a3-8473c78f33cd"
      },
      "source": [
        "### PinderDataset (torch Dataset)\n",
        "\n",
        "\n",
        "The `PinderDataset` is an example implementation of a `torch.utils.data.Dataset` that represents its data items as a dict containing the following key, value pairs:\n",
        "* `target_complex`: The ground-truth holo dimer, represented with a set of default properties encoded as `Tensor`'s\n",
        "* `feature_complex`: The sampled dimer complex, representing \"features\", also represented with a set of default properties encoded as `Tensor`'s\n",
        "* `id`: The pinder ID for the selected system\n",
        "* `target_id`: The IDs of the receptor and ligand holo monomers, concatenated into a single ID string\n",
        "* `sample_id`: The IDs of the sampled receptor and ligand holo monomers, concatenated into a single ID string. This can be useful for debugging purposes or generally tracking which specific monomers are selected when targeting alternative monomers (more on this shortly)\n",
        "\n",
        "\n",
        "Each of the `target_complex` and `feature_complex` values are dictionaries with structural properties encoded by the `pinder.core.loader.geodata.structure2tensor` function by default:\n",
        "* `atom_coordinates`\n",
        "* `atom_types`\n",
        "* `chain_ids`\n",
        "* `residue_coordinates`\n",
        "* `residue_types`\n",
        "* `residue_ids`\n",
        "\n",
        "You can choose to use a different representation by overriding the default values of `transform` and `target_transform`.\n",
        "\n",
        "It leverages the `PinderLoader` to apply optional filters and/or transforms, provide an interface for sampling alternative monomers, and exposes `transform` and `target_transform` arguments used by the torch Dataset API.\n",
        "\n",
        "For more details on the torch Dataset APIs, please refer to the [tutorials](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#datasets-dataloaders).\n",
        "\n",
        "#### Example `PinderDataset`\n",
        "\n",
        "Now, we'll go through an example dataset preparation using the `PinderDataset` built on PyTorch `Dataset`. We start by merging our structure index with relevant metadata such as resolution and experimental method. Then, we define a handy `get_subset` function to filter out low-quality or irrelevant structures.\n",
        "\n",
        "We'll do this by limiting it to systems determined by X-ray diffraction with biologically relevant interactions. To make our initial experiments faster and more manageable, we'll sample a small subset of 10 structures each for training and validation. Finally, we'll grab one random sample from the test set to showcase our model's predictions later on. This careful data preparation sets the stage for effective model training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = get_index()\n",
        "metadata = get_metadata()\n",
        "\n",
        "index = pd.merge(index, metadata[[\"id\", \"resolution\", \"label\", \"method\"]], on=\"id\")\n",
        "\n",
        "# We'll start by restricting the training and validataion datasets to a smaller size (10) for testing purposes.\n",
        "\n",
        "def get_subset(index, split, n_samples=50):\n",
        "    query = '(resolution < 2) and (method == \"X-RAY DIFFRACTION\") and (label == \"BIO\")'\n",
        "    n_samples = n_samples\n",
        "    subset = index.query(f'{query} and (split == \"{split}\")').sample(n_samples).reset_index(drop=True, inplace=False).id.to_list()\n",
        "    return subset\n",
        "\n",
        "n_samples = 10\n",
        "training_subset = get_subset(index, \"train\", n_samples)\n",
        "validation_subset = get_subset(index, \"val\", n_samples)\n",
        "test_subset = get_subset(index, \"test\", 1) # take a random test as example case"
      ],
      "metadata": {
        "id": "2IS78ys4e-vC"
      },
      "id": "2IS78ys4e-vC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9658c6aa-5720-4c0f-98ae-b79d34ad2754",
      "metadata": {
        "id": "9658c6aa-5720-4c0f-98ae-b79d34ad2754"
      },
      "outputs": [],
      "source": [
        "from pinder.core.loader.dataset import PinderDataset, structure2tensor_transform\n",
        "from pinder.core.loader import filters, transforms\n",
        "\n",
        "# We'll start by restricting the training dataset to a smaller size (10) for testing purposes.\n",
        "\n",
        "base_filters = [\n",
        "    filters.FilterByMissingHolo(),\n",
        "    filters.FilterSubByContacts(min_contacts=5, radius=10.0, calpha_only=True),\n",
        "    filters.FilterDetachedHolo(radius=12, max_components=2),\n",
        "]\n",
        "sub_filters = [\n",
        "    filters.FilterSubByAtomTypes(min_atom_types=4),\n",
        "    filters.FilterByHoloOverlap(min_overlap=5),\n",
        "    filters.FilterByHoloSeqIdentity(min_sequence_identity=0.8),\n",
        "    filters.FilterSubRmsds(rmsd_cutoff=7.5),\n",
        "    filters.FilterDetachedSub(radius=12, max_components=2),\n",
        "]\n",
        "\n",
        "\n",
        "# We can include Structure-level transforms (and filters) which will operate on the target and/or feature complexes\n",
        "target_transforms = [\n",
        "    transforms.SelectAtomTypes(atom_types=[\"CA\", \"N\", \"C\", \"O\"]),\n",
        "]\n",
        "# In addition to slicing only backbone atoms, we introduce random rotation to the ligand protein\n",
        "# in the feature complex while preserving the target (ground-truth) complex orientations.\n",
        "feature_transforms = [\n",
        "    transforms.SelectAtomTypes(atom_types=[\"CA\", \"N\", \"C\", \"O\"]),\n",
        "    transforms.RandomLigandTransform(max_translation=10.0),\n",
        "]\n",
        "\n",
        "datasets = []\n",
        "\n",
        "for split, subset_ids in [(\"train\", training_subset), (\"val\", validation_subset), (\"test\", test_subset)]:\n",
        "    print(f\"Loading {split} split with {len(subset_ids)} systems...\")\n",
        "    dataset = PinderDataset(\n",
        "        split=split,\n",
        "        ids=subset_ids,\n",
        "        # We can leverage holo, apo, pred, random and random_mixed monomer sampling strategies\n",
        "        monomer_priority=\"random_mixed\" if split != \"test\" else \"holo\",\n",
        "        base_filters = base_filters,\n",
        "        sub_filters = sub_filters,\n",
        "        structure_transforms_target=target_transforms,\n",
        "        structure_transforms_feature=feature_transforms)\n",
        "    datasets.append(dataset)\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = datasets\n",
        "\n",
        "assert len(train_dataset) == len(training_subset) == n_samples\n",
        "assert len(test_subset) == 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "beadbaca-17e4-4c8f-981d-277e702e640a",
      "metadata": {
        "id": "beadbaca-17e4-4c8f-981d-277e702e640a"
      },
      "source": [
        "### Sampling alternative monomers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa2cf4cf-58f9-4ad8-8b89-eb961f141c66",
      "metadata": {
        "id": "fa2cf4cf-58f9-4ad8-8b89-eb961f141c66"
      },
      "source": [
        "The `monomer_priority` argument can be used to target different mixes of bound and unbound monomers to use for creating the decoy/feature complex.\n",
        "\n",
        "The allowed values for `monomer_priority` are \"apo\", \"holo\", \"pred\", \"random\" or \"random_mixed\".\n",
        "\n",
        "When `monomer_priority` is set to one of the available monomer types (holo, apo, pred), the same monomer type will be selected for both receptor and ligand.\n",
        "\n",
        "When the monomer priority is \"random\", a random monomer type will be selected from the set of monomer types available for both the receptor and ligand. This option ensures the same type of monomer is used for the receptor and ligand.\n",
        "\n",
        "When the monomer priority is \"random_mixed\", a random monomer type will be selected for each of receptor and ligand, separately.\n",
        "\n",
        "Enabling the `fallback_to_holo` option (default) will enable silent fallback to holo when the `monomer_priority` is set to one of apo or pred, but the corresponding monomer is not available for the dimer.\n",
        "\n",
        "This is useful when only one of receptor or ligand has an unbound monomer, but you wish to include apo or predicted structures in your workflow.\n",
        "\n",
        "If `fallback_to_holo` is disabled, an error will be raised when the `monomer_priority` is set to one of apo or pred, but the corresponding monomer is not available for the dimer.\n",
        "\n",
        "\n",
        "By default, when apo monomers are selected, the \"canonical\" apo monomer is used. Although a single canonical apo monomer should be used for eval, pinder provides multiple apo monomers paired to a single holo monomer (when available). In order to include these non-canonical/alternative monomers, you can specify `use_canonical_apo=False` when constructing the `PinderLoader` or `PinderDataset` objects.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "383244d7-1a85-4732-9dd4-3455fe4cec88",
      "metadata": {
        "id": "383244d7-1a85-4732-9dd4-3455fe4cec88"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "data_item = train_dataset[0]\n",
        "pprint(data_item)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(data_item[\"feature_complex\"])"
      ],
      "metadata": {
        "id": "0hVeS75DN-51"
      },
      "id": "0hVeS75DN-51",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a6f64b4-f027-4286-b444-68cd9f6b59a4",
      "metadata": {
        "id": "4a6f64b4-f027-4286-b444-68cd9f6b59a4"
      },
      "outputs": [],
      "source": [
        "# Since we used the default option of crop_equal_monomer_shapes, we should expect feature and target complex coords are identical shapes\n",
        "assert (\n",
        "    data_item[\"feature_complex\"][\"atom_coordinates\"].shape\n",
        "    == data_item[\"target_complex\"][\"atom_coordinates\"].shape\n",
        ")\n",
        "\n",
        "data_item[\"feature_complex\"][\"atom_coordinates\"].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01025b2b-1962-43b3-8c4e-a33b6a3d6231",
      "metadata": {
        "id": "01025b2b-1962-43b3-8c4e-a33b6a3d6231"
      },
      "outputs": [],
      "source": [
        "help(PinderDataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bea7b003-2ffc-4660-b1c8-a03cfe5086d2",
      "metadata": {
        "id": "bea7b003-2ffc-4660-b1c8-a03cfe5086d2"
      },
      "source": [
        "### Torch DataLoader for PinderDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44316aac-dca9-4902-89c3-96de91e640cb",
      "metadata": {
        "id": "44316aac-dca9-4902-89c3-96de91e640cb"
      },
      "source": [
        "The `PinderDataset` can be served by a `torch.utils.data.DataLoader`.\n",
        "\n",
        "There is a convenience function `pinder.core.loader.dataset.get_torch_loader` for taking a `PinderDataset` and returning a `DataLoader` for the dataset object.\n",
        "\n",
        "We can leverage the default `collate_fn` (`pinder.core.loader.dataset.collate_batch`) to merge multiple systems (`Dataset` items) to create mini-batches of tensors:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcb50bed-7e0a-4d4b-a1d7-6bc003161aab",
      "metadata": {
        "id": "fcb50bed-7e0a-4d4b-a1d7-6bc003161aab"
      },
      "outputs": [],
      "source": [
        "from pinder.core.loader.dataset import collate_batch, get_torch_loader\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 2\n",
        "train_dataloader = get_torch_loader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_batch,\n",
        "    num_workers=0,\n",
        ")\n",
        "assert isinstance(train_dataloader, DataLoader)\n",
        "assert hasattr(train_dataloader, \"dataset\")\n",
        "\n",
        "# Get a batch from the dataloader\n",
        "batch = next(iter(train_dataloader))\n",
        "\n",
        "# expected batch dict keys\n",
        "assert set(batch.keys()) == {\n",
        "    \"target_complex\",\n",
        "    \"feature_complex\",\n",
        "    \"id\",\n",
        "    \"sample_id\",\n",
        "    \"target_id\",\n",
        "}\n",
        "assert isinstance(batch[\"target_complex\"], dict)\n",
        "assert isinstance(batch[\"target_complex\"][\"atom_coordinates\"], torch.Tensor)\n",
        "feature_coords = batch[\"feature_complex\"][\"atom_coordinates\"]\n",
        "\n",
        "# Ensure batch size propagates to tensor dims\n",
        "assert feature_coords.shape[0] == batch_size\n",
        "\n",
        "# Ensure coordinates have dim 3\n",
        "assert feature_coords.shape[2] == 3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Break - Q&A"
      ],
      "metadata": {
        "id": "sFjjZpNazptK"
      },
      "id": "sFjjZpNazptK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train a model\n",
        "\n",
        "Now, we'll use a \"dummy\" model to explore the `PinderDataset` further. Given a complex, we're going to predict the rotation and translation of the ligand.\n",
        "\n",
        "This has direct application to the rigid docking task, where we assume the ligand's internal structure doesn't change during docking. We'll use a straightforward iterator to handle batched data during training. The model's forward pass will output the predicted rotation and translation, as well as the transformed position of the ligand.\n",
        "\n",
        "We'll measure the accuracy of our predictions with the Mean Squared Error loss of the predicted vs ground truth ligand coordinates.\n",
        "\n",
        "Finally, we'll demonstrate how the inferred rotation and translation can be used to write the docking results as PDB and evaluate using `pinder-eval`."
      ],
      "metadata": {
        "id": "VIwmiEHQT-cy"
      },
      "id": "VIwmiEHQT-cy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dummy model implementation\n",
        "\n",
        "The `DummyModelPredRotTrans` class defines a PyTorch `Module` for predicting the rotation and translation of a ligand, given a random initial pose. We'll use this model as an example for the training and eval workflow using `pinder`'s existing functionalities."
      ],
      "metadata": {
        "id": "xrp6AkeK_Uqt"
      },
      "id": "xrp6AkeK_Uqt"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class DummyModelPredRotTrans(nn.Module):\n",
        "    \"\"\"\n",
        "    A simple model for predicting rotation and translation of a ligand given its coordinates and those of the receptor.\n",
        "\n",
        "    Pipeline:\n",
        "    1. A multi-layer perceptron (MLP) to embed the receptor and ligand coordinates.\n",
        "    2. Cross-attention between the receptor and ligand.\n",
        "    3. Finally, it predicts the rotation matrix and translation vector.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, embed_dim, num_heads):\n",
        "        \"\"\"\n",
        "        Initialize the model.\n",
        "\n",
        "        Args:\n",
        "            input_dim: The dimension of the input features.\n",
        "            embed_dim: The dimension of the embedding space.\n",
        "            num_heads: The number of attention heads in the multi-head attention layer.\n",
        "        \"\"\"\n",
        "        super(DummyModelPredRotTrans, self).__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(input_dim, embed_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(embed_dim, embed_dim),\n",
        "            nn.LayerNorm(embed_dim)  # Added normalization layer\n",
        "        )\n",
        "        self.cross_attention = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
        "        self.fc_rotation = nn.Linear(embed_dim, 9)\n",
        "        self.fc_translation = nn.Linear(embed_dim, 3)\n",
        "\n",
        "    def naive_single(self, receptor, ligand):\n",
        "        \"\"\"\n",
        "        Processes a single receptor-ligand pair.\n",
        "\n",
        "        Args:\n",
        "            receptor: Tensor of shape (1, num_receptor_atoms, 3) (receptor coordinates)\n",
        "            ligand: Tensor of shape (1, num_ligand_atoms, 3) (ligand coordinates)\n",
        "\n",
        "        Returns:\n",
        "            rotation_matrix: Tensor of shape (1, 3, 3) predicted rotation matrix for the ligand.\n",
        "            translation_vector: Tensor of shape (1, 3) predicted translation vector for the ligand.\n",
        "        \"\"\"\n",
        "        emb_features_receptor, emb_features_ligand = self.mlp(receptor), self.mlp(ligand)\n",
        "        attn_output, _ = self.cross_attention(emb_features_receptor, emb_features_ligand, emb_features_ligand)\n",
        "        rotation_matrix = self.fc_rotation(attn_output.mean(dim=1))\n",
        "        rotation_matrix = rotation_matrix.view(-1, 3, 3)\n",
        "        translation_vector = self.fc_translation(attn_output.mean(dim=1))\n",
        "        return rotation_matrix, translation_vector\n",
        "\n",
        "    def forward_rot_trans(self, batch):\n",
        "        \"\"\"\n",
        "        Predicts rotation and translation for a batch of receptor-ligand complexes.\n",
        "\n",
        "        Args:\n",
        "            batch: A dictionary containing the batch data. It should have the following keys:\n",
        "                - \"feature_complex\": A dictionary containing:\n",
        "                    - \"atom_coordinates\": Tensor of shape (batch_size, num_atoms, 3) representing atom coordinates.\n",
        "                    - \"chain_ids\": Tensor of shape (batch_size, num_atoms) representing chain IDs (0 for receptor, 1 for ligand).\n",
        "\n",
        "        Returns:\n",
        "            rotation_matrix: Tensor of shape (batch_size, 3, 3) representing predicted rotation matrices.\n",
        "            translation_vector: Tensor of shape (batch_size, 3) representing predicted translation vectors.\n",
        "            ligands: List of tensors, each of shape (1, num_ligand_atoms, 3), representing the original ligand coordinates.\n",
        "        \"\"\"\n",
        "        rotation_matrices = []\n",
        "        translation_vectors = []\n",
        "        ligands = []\n",
        "        for i in range(batch[\"feature_complex\"][\"chain_ids\"].shape[0]):\n",
        "            current_complex_coords = batch[\"feature_complex\"][\"atom_coordinates\"][i]\n",
        "            ligand_mask = batch[\"feature_complex\"][\"chain_ids\"][i] == 1\n",
        "            receptor_mask = batch[\"feature_complex\"][\"chain_ids\"][i] == 0\n",
        "            ligand_coords = current_complex_coords[ligand_mask]\n",
        "            receptor_coords = current_complex_coords[receptor_mask]\n",
        "            ligand_coords = ligand_coords.unsqueeze(0)\n",
        "            receptor_coords = receptor_coords.unsqueeze(0)\n",
        "            rotation_matrix, translation_vector = self.naive_single(receptor_coords, ligand_coords)\n",
        "            rotation_matrices.append(rotation_matrix)\n",
        "            translation_vectors.append(translation_vector)\n",
        "            ligands.append(ligand_coords)\n",
        "        rotation_matrix = torch.stack(rotation_matrices)\n",
        "        translation_vector = torch.stack(translation_vectors)\n",
        "        return rotation_matrix, translation_vector, ligands\n",
        "\n",
        "    def forward(self, batch):\n",
        "        \"\"\"\n",
        "        The main forward pass of the model.\n",
        "\n",
        "        Args:\n",
        "            batch: Same as in forward_rot_trans.\n",
        "\n",
        "        Returns:\n",
        "            transformed_ligands: List of tensors, each of shape (1, num_ligand_atoms, 3)\n",
        "            representing the transformed ligand coordinates after applying the predicted\n",
        "            rotation and translation.\n",
        "        \"\"\"\n",
        "        rotation_matrix, translation_vector, ligands = self.forward_rot_trans(batch)\n",
        "        for i in range(len(ligands)):\n",
        "            ligands[i] = ligands[i] @ rotation_matrix[i] + translation_vector[i]\n",
        "        return ligands"
      ],
      "metadata": {
        "id": "Zwjd1rgn_YWe"
      },
      "id": "Zwjd1rgn_YWe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model hyperparameters\n",
        "input_dim = 3  # 3D coordinates (x, y, z)\n",
        "embed_dim = 4  # Dimension of the embedding space after MLP transformation\n",
        "num_heads = 1  # Number of attention heads for cross-attention\n",
        "\n",
        "# Instantiate the model\n",
        "model = DummyModelPredRotTrans(input_dim, embed_dim, num_heads)\n",
        "\n",
        "# Get a sample batch from the training dataloader\n",
        "batch = next(iter(train_dataloader))\n",
        "# Perform a forward pass to get predicted ligand coordinates\n",
        "with torch.inference_mode():\n",
        "    predicted_ligand_coords = model(batch)\n",
        "\n",
        "# Verify output dimensions: Ensure the number of predicted ligand coordinates matches the actual number of ligand atoms in the batch\n",
        "for i in range(len(predicted_ligand_coords)):\n",
        "    assert predicted_ligand_coords[i].shape[1] == (batch[\"target_complex\"][\"chain_ids\"][i] == 1).sum()"
      ],
      "metadata": {
        "id": "JbHJ93x-_g7o"
      },
      "id": "JbHJ93x-_g7o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and validation"
      ],
      "metadata": {
        "id": "w5Siiv0r_RkF"
      },
      "id": "w5Siiv0r_RkF"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "def loss_fn(pred_l, gt_l, masks):\n",
        "    \"\"\"\n",
        "    Calculates the MSE loss between predicted and ground truth ligand coordinates\n",
        "    for the batch.\n",
        "\n",
        "    Args:\n",
        "        pred_l: predicted ligand coordinates.\n",
        "        gt_l: ground truth coordinates for the entire complex.\n",
        "        masks: tensor representing chain IDs (0 for receptor, 1 for ligand).\n",
        "\n",
        "    Returns:\n",
        "        The mean MSE loss for batch.\n",
        "    \"\"\"\n",
        "    losses = []\n",
        "    for i in range(len(pred_l)):\n",
        "        pred_l_i = pred_l[i]\n",
        "        gt_l_i = gt_l[i][masks[i] == 1].unsqueeze(0)\n",
        "        losses.append(F.mse_loss(pred_l_i, gt_l_i))\n",
        "    return torch.mean(torch.stack(losses))\n",
        "\n",
        "def validation_loop(dataloader, model):\n",
        "    \"\"\"\n",
        "    Performs validation on the given dataloader and model.\n",
        "\n",
        "    Args:\n",
        "        dataloader: The dataloader for the validation set.\n",
        "        model: The model to be evaluated.\n",
        "\n",
        "    Returns:\n",
        "        The mean MSE loss for all batches.\n",
        "    \"\"\"\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    val_losses = []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            pred_l = model(batch)\n",
        "            val_loss = loss_fn(pred_l,\n",
        "                                batch[\"target_complex\"][\"atom_coordinates\"],\n",
        "                                batch[\"target_complex\"][\"chain_ids\"]).item()\n",
        "            val_losses.append(val_loss)\n",
        "    print(f\"Validation loss: {np.mean(val_losses):>8f}\")\n",
        "    return val_losses\n",
        "\n",
        "def train_loop(train_dataloader, val_dataloader, model, optimizer, num_epoch=10, val_interval=1):\n",
        "    \"\"\"\n",
        "    Trains the model.\n",
        "\n",
        "    Args:\n",
        "        train_dataloader: The dataloader for the training set.\n",
        "        val_dataloader: The dataloader for the validation set.\n",
        "        model: The model to be trained.\n",
        "        optimizer: The optimizer used for training.\n",
        "        num_epoch: The number of epochs to train for.\n",
        "        val_interval: The interval (in epochs) at which to perform validation.\n",
        "    \"\"\"\n",
        "    loss_log = []\n",
        "    for epoch in range(num_epoch):\n",
        "        print(f\"\\nEpoch {epoch+1}\\n-------------------------------\")\n",
        "        size = len(train_dataloader.dataset)\n",
        "        for batch in train_dataloader:\n",
        "\n",
        "            # Compute prediction and loss\n",
        "            pred_l = model(batch)\n",
        "            loss = loss_fn(pred_l,\n",
        "                           batch[\"target_complex\"][\"atom_coordinates\"],\n",
        "                           batch[\"target_complex\"][\"chain_ids\"])\n",
        "\n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        if epoch % val_interval == 0:\n",
        "            val_losses = validation_loop(val_dataloader, model)\n",
        "            loss_log.extend([{\"epoch\": epoch, \"val/loss\": vl} for vl in val_losses])\n",
        "    return pd.DataFrame(loss_log)\n",
        "\n"
      ],
      "metadata": {
        "id": "1uldwF-JUNpl"
      },
      "id": "1uldwF-JUNpl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also create the dataloaders for `val` and `test` datasets"
      ],
      "metadata": {
        "id": "h6PvsN418XBA"
      },
      "id": "h6PvsN418XBA"
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataloader = get_torch_loader(\n",
        "    val_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_batch,\n",
        "    num_workers=0,\n",
        ")\n",
        "\n",
        "test_dataloader = get_torch_loader(\n",
        "    test_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        ")\n",
        "# We can start the training for 5 epochs\n",
        "val_loss = train_loop(train_dataloader, val_dataloader, model, optimizer, num_epoch=5)\n"
      ],
      "metadata": {
        "id": "5qp3mmTLhRCW"
      },
      "id": "5qp3mmTLhRCW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "fig = px.line(\n",
        "    val_loss.groupby(\"epoch\", as_index=False)[\"val/loss\"].mean(),\n",
        "    x=\"epoch\",\n",
        "    y=\"val/loss\",\n",
        "    template=\"plotly_dark\",\n",
        "    title=\"Mean validation MSE loss\",\n",
        "    width=850, height=650,\n",
        ")\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "YLxRClzrug3G"
      },
      "id": "YLxRClzrug3G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference\n",
        "\n",
        "Our test data contains a single example, we can use our model to make predictions on the test."
      ],
      "metadata": {
        "id": "lK37Ii2ahKe3"
      },
      "id": "lK37Ii2ahKe3"
    },
    {
      "cell_type": "code",
      "source": [
        "test_batch = next(iter(test_dataloader))\n",
        "with torch.inference_mode():\n",
        "  predicted_ligand_coords = model(test_batch)\n"
      ],
      "metadata": {
        "id": "FEe2UcVMhOuE"
      },
      "id": "FEe2UcVMhOuE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can see more info on our test data\n",
        "test_dataloader.dataset.loader.index"
      ],
      "metadata": {
        "id": "mlEn4BHHeitH"
      },
      "id": "mlEn4BHHeitH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_index = test_dataloader.dataset.loader.index\n",
        "loaded_idx = test_index[test_index[\"id\"] == test_batch['id'][0]].index.values[0]\n",
        "loaded_idx"
      ],
      "metadata": {
        "id": "Vc7YaMueKTgo"
      },
      "id": "Vc7YaMueKTgo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_ligand_coords[0].shape"
      ],
      "metadata": {
        "id": "YbmkX7ZHKDIu"
      },
      "id": "YbmkX7ZHKDIu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now we can load them as pinder's Structure objects\n",
        "system, feature_complex, target_complex = test_dataloader.dataset.loader[loaded_idx]"
      ],
      "metadata": {
        "id": "DK7Wt9BfKK0W"
      },
      "id": "DK7Wt9BfKK0W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# take the predicted coords of the ligand and convert to numpy array\n",
        "pred_coords = predicted_ligand_coords[0].detach().numpy()[0]\n",
        "# make sure ligand coordinate dimensions match with the original input complex dimensions\n",
        "assert pred_coords.shape[0] == (feature_complex.atom_array.chain_id == \"L\").sum()"
      ],
      "metadata": {
        "id": "rIhpXmllLDAR"
      },
      "id": "rIhpXmllLDAR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DiwPpVEDc4hd"
      },
      "id": "DiwPpVEDc4hd"
    },
    {
      "cell_type": "code",
      "source": [
        "# we can now edit the structure object with the new predicted coords\n",
        "feature_complex.atom_array[feature_complex.atom_array.chain_id == \"L\"].coord = pred_coords"
      ],
      "metadata": {
        "id": "vVwo0TW8LZll"
      },
      "id": "vVwo0TW8LZll",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import biotite.structure as struc\n",
        "\n",
        "# Superimpose predicted receptor chain to ground-truth receptor chain using biotite\n",
        "nat_arr = target_complex.atom_array.copy()\n",
        "pred_arr = feature_complex.atom_array.copy()\n",
        "_, transformation = struc.superimpose(nat_arr[nat_arr.chain_id == \"R\"], pred_arr[pred_arr.chain_id == \"R\"])\n",
        "pred_arr = transformation.apply(pred_arr)\n",
        "feature_complex.atom_array = pred_arr.copy()\n",
        "\n"
      ],
      "metadata": {
        "id": "WgCsWrizky97"
      },
      "id": "WgCsWrizky97",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "# Write the prediction to PDB to visualize\n",
        "output_pdb = Path('./predicted_model_rank1.pdb')\n",
        "feature_complex.to_pdb(output_pdb)"
      ],
      "metadata": {
        "id": "itLhj6YbmHVo"
      },
      "id": "itLhj6YbmHVo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import py3Dmol\n",
        "\n",
        "# Viewer documentation: https://3dmol.org/doc/GLViewer.html\n",
        "view = py3Dmol.view(width=900, height=900)\n",
        "view.removeAllModels()\n",
        "view.setViewStyle({'style':'outline','color':'black','width':0.1})\n",
        "view.setBackgroundColor('black')\n",
        "0\n",
        "# Show the reference structure\n",
        "\n",
        "ps = PinderSystem(test_batch['id'][0])\n",
        "ref_pdb = ps.native.filepath\n",
        "view.addModel(open(ref_pdb, 'r').read(),'pdb',\n",
        "             {\"style\": {'cartoon': {'color':'gold'}}})\n",
        "\n",
        "\n",
        "view.setStyle({'chain':'R'},{'cartoon': {'color':'gray', 'arrows':True, 'tubes': False, 'ribbon': False, 'style': 'edged'}})\n",
        "view.setStyle({'chain':'L'},{'cartoon': {'color':'gold', 'arrows':True, 'tubes':False, 'ribbon': False, 'style':'edged'}})\n",
        "\n",
        "# Show the receptor-chain superposed model structure\n",
        "view.addModel(\n",
        "    open(output_pdb, 'r').read(),\n",
        "    'pdb',\n",
        "    {\"style\": {'cartoon': {'color':'lightgray'}}}\n",
        ")\n",
        "# Color the predicted ligand chain in light pink\n",
        "view.setStyle({'chain':'L', \"model\": 1},{'cartoon': {'color':'lightpink', 'arrows':True, 'tubes': False, 'ribbon': False, 'style': 'edged'}})\n",
        "view.zoomTo()\n",
        "view.show()"
      ],
      "metadata": {
        "id": "ubJEzrTPMGIl"
      },
      "id": "ubJEzrTPMGIl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the prediction\n",
        "\n",
        "from pinder.eval.dockq import BiotiteDockQ\n",
        "ps = PinderSystem(test_batch['id'][0])\n",
        "ref_pdb = ps.native.filepath\n",
        "bdq = BiotiteDockQ(ref_pdb, output_pdb, parallel_io=False)\n",
        "metrics = bdq.calculate()\n",
        "metrics.T\n"
      ],
      "metadata": {
        "id": "MjxXLQ-Fh58P"
      },
      "id": "MjxXLQ-Fh58P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--molWXKS6ZL"
      },
      "source": [
        "## Pinder eval"
      ],
      "id": "--molWXKS6ZL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xR-CZI9ES6ZL"
      },
      "source": [
        "The evaluation harness can be used either through methods in `pinder.eval` or as a CLI script:\n",
        "\n",
        "\n",
        "```\n",
        "pinder_eval --help\n",
        "\n",
        "usage: pinder_eval [-h] --eval_dir eval_dir [--serial] [--method_name method_name] [--allow_missing]\n",
        "\n",
        "optional arguments:\n",
        "  -h, --help            show this help message and exit\n",
        "  --eval_dir eval_dir, -f eval_dir\n",
        "                        Path to eval\n",
        "  --serial, -s          Whether to disable parallel eval over systems\n",
        "  --method_name method_name, -m method_name, -n method_name\n",
        "                        Optional name for output csv\n",
        "  --allow_missing, -a   Whether to allow missing systems for a given pinder-set + monomer\n",
        "\n",
        "```\n",
        "\n",
        "The expected format for the contents of `eval_dir` are shown below:\n",
        "```\n",
        "eval_dir_example/\n",
        "‚îî‚îÄ‚îÄ some_method\n",
        "    ‚îú‚îÄ‚îÄ 1ldt__A1_P00761--1ldt__B1_P80424\n",
        "    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ apo_decoys\n",
        "    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ model_1.pdb\n",
        "    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ model_2.pdb\n",
        "    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ holo_decoys\n",
        "    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ model_1.pdb\n",
        "    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ model_2.pdb\n",
        "    ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ predicted_decoys\n",
        "    ‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ model_1.pdb\n",
        "    ‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ model_2.pdb\n",
        "    ‚îî‚îÄ‚îÄ 1b8m__B1_P34130--1b8m__A1_P23560\n",
        "        ‚îú‚îÄ‚îÄ holo_decoys\n",
        "        ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ model_1.pdb\n",
        "        ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ model_2.pdb\n",
        "        ‚îî‚îÄ‚îÄ predicted_decoys\n",
        "            ‚îú‚îÄ‚îÄ model_1.pdb\n",
        "            ‚îî‚îÄ‚îÄ model_2.pdb\n",
        "```\n",
        "\n",
        "The eval directory should contain one or more methods to evaluate as sub-directories.\n",
        "\n",
        "Each method sub-directory should contains sub-directories that are named by pinder system ID.\n",
        "\n",
        "Inside of each pinder system sub-directory, you should have three subdirectories:\n",
        "* `holo_decoys` (predictions that were made using holo monomers)\n",
        "* `apo_decoys` (predictions made using apo monomers)\n",
        "* `predicted_decoys` (predictions made using predicted, e.g. AF2, monomers)\n",
        "\n",
        "You can have any number of decoys in each directory; however, the decoys should be named in a way that the prediction rank can be extracted. In the above example, the decoys are named using a `model_<rank>.pdb` convention. Other names for decoy models are accepted, so long as they can match the regex pattern used in `pinder.eval.dockq.MethodMetrics`: `r\"\\d+(?=\\D*$)\"`\n",
        "\n",
        "Each model decoy should have exactly two chains: {R, L} for {Receptor, Ligand}, respectively.\n",
        "\n",
        "\n",
        "‚ö†Ô∏è **Note: in order to make a fair comparison of methods across complete test sets, if a method is missing predictions for a system, the following metrics are used as a penalty**\n",
        "\n",
        "```python\n",
        "\n",
        "{\n",
        "    \"iRMS\": 100.0,\n",
        "    \"LRMS\": 100.0,\n",
        "    \"Fnat\": 0.0,\n",
        "    \"DockQ\": 0.0,\n",
        "    \"CAPRI\": \"Incorrect\",\n",
        "}\n",
        "```\n"
      ],
      "id": "xR-CZI9ES6ZL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boVecYJ8S6ZL"
      },
      "source": [
        "Under the hood, the leaderboard makes use of the `MethodMetrics` class from the `pinder.eval.dockq.method`. This interface is itself an abstraction over the underlying `BiotiteDockQ` API.\n",
        "\n",
        "Below I show an example of how you could use the `BiotiteDockQ` class directly."
      ],
      "id": "boVecYJ8S6ZL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jiefiL5S6ZL"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "from pathlib import Path\n",
        "from pinder.eval.dockq.biotite_dockq import BiotiteDockQ\n",
        "\n",
        "method_dir = Path(\"./dummy-model\").absolute()\n",
        "system_dir = method_dir / test_batch['id'][0]\n",
        "decoy_dir = system_dir / \"holo_decoys\"\n",
        "decoy_dir.mkdir(exist_ok=True, parents=True)\n",
        "if not (decoy_dir / output_pdb.name).is_file():\n",
        "    shutil.copy(output_pdb, decoy_dir)\n",
        "\n",
        "native = ps.native.filepath\n",
        "decoys = list(decoy_dir.glob(\"*.pdb\"))\n",
        "\n",
        "R_chain, L_chain = [\"R\"], [\"L\"]\n",
        "bdq = BiotiteDockQ(\n",
        "    native=native, decoys=decoys,\n",
        "    # These are optional and if not specified will be assigned based on number of atoms (receptor > ligand)\n",
        "    native_receptor_chain=R_chain,\n",
        "    native_ligand_chain=L_chain,\n",
        "    decoy_receptor_chain=R_chain,\n",
        "    decoy_ligand_chain=L_chain,\n",
        ")\n",
        "metrics = bdq.calculate()\n",
        "metrics\n"
      ],
      "id": "3jiefiL5S6ZL"
    },
    {
      "cell_type": "code",
      "source": [
        "from pinder.eval.dockq.method import MethodMetrics\n",
        "\n",
        "mm = MethodMetrics(method_dir, allow_missing_systems=True, parallel=False)\n",
        "metrics = mm.metrics\n",
        "metrics"
      ],
      "metadata": {
        "id": "rfAJOFpYxrh1"
      },
      "id": "rfAJOFpYxrh1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "leaderboard_row = mm.get_leaderboard_entry()\n",
        "leaderboard_row.T"
      ],
      "metadata": {
        "id": "B6_wDOh0yoV4"
      },
      "id": "B6_wDOh0yoV4",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pinder",
      "language": "python",
      "name": "pinder"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}